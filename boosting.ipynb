{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import evaluate\n",
    "import merge\n",
    "import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load evaluation data\n",
    "test_columns = ['returnQuantity', 'articleID', 'productGroup', 'customerID', 'voucherID']\n",
    "test_predictions = merge.merged_predictions(test=True, keep_columns=test_columns)\n",
    "test_train = evaluate.test_complement(test_predictions)\n",
    "\n",
    "# Load classification data\n",
    "class_columns = ['articleID', 'productGroup', 'customerID', 'voucherID',]\n",
    "class_predictions = merge.merged_predictions(keep_columns=class_columns)\n",
    "class_train = load.orders_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Impute zeroes and convert confidenes to std-distances\n",
    "class_imputed = merge.impute_confidence(class_predictions)\n",
    "test_imputed = merge.impute_confidence(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 4: Boost results using another classifier\n",
    "Due to lack of comparability between confidence values and the probably problematic imputation of confidence values it might be interesting to follow the approach of Boosting. This means we look at the results the respective classifiers gave and try to vote always for the best in a given case. Imposing this as a machine learning problem we have as feature vector\n",
    "$\\boldsymbol{t}_k=(pred_k^A, pred_k^B, prediction_k^C, conf_k^A, conf_k^B, conf_k^C, art_k, cust_k, voucher_k, prod_k)$ while the last four arguments are binary and tell us if the respective category is known before evaluation. Further as target we have again class labels which refer binarily to *returned* or *not returned*. Thus, we have $y=returned, y \\in \\{0,1\\}$ as possible labels.\n",
    "\n",
    "We already know from section **Highest possible precision** that in around 21% of the rows we find disagreement. All other rows are not interesting for this problem and we won't touch them or learn anything from them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline - Only using the most precise classifier\n",
    "Is there one result which we can always use to resolve disagreement? We have to look at different performances when classifiers disagree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69993014003494847"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agree_mask = ((test_predictions.prediction.A == test_predictions.prediction.B) & \n",
    "              (test_predictions.prediction.A == test_predictions.prediction.C))\n",
    "baseline = merge.precision(test_predictions.original.returnQuantity[agree_mask],\n",
    "                           test_predictions.prediction.B[agree_mask])\n",
    "baseline_weight = len(preds[agree_mask])\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If classifiers agree, the precision is near 70% which is extremely good in comparison to single results. This shows that the 21% disagreement make a huge difference in classification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disagree_mask = ((test_predictions.prediction.A != test_predictions.prediction.B) | \n",
    "                 (test_predictions.prediction.A != test_predictions.prediction.C))\n",
    "y_labels = test_predictions.original.returnQuantity[disagree_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A, B, C on disagreement (baseline for boosting on disagreed rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45814186362326992, 0.54310640457606896, 0.55259187116774799)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = merge.precision(y_labels, test_predictions.prediction.A[disagree_mask])\n",
    "b = merge.precision(y_labels, test_predictions.prediction.B[disagree_mask])\n",
    "c = merge.precision(y_labels, test_predictions.prediction.C[disagree_mask])\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing accuracy using DecisionTree and SVM with k-fold parameter optimization and k-fold cross validation for final estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn import grid_search\n",
    "from sklearn import cross_validation\n",
    "from sklearn import pipeline\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import ensemble\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = ['articleID', 'productGroup', 'customerID', 'voucherID']\n",
    "X, y = merge.boosting_features(test_train, test_imputed, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.55259187116774799, 0.55260558840070784)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = [('scaling', preprocessing.StandardScaler()),\n",
    "         ('svm', svm.SVC())]\n",
    "clf = pipeline.Pipeline(steps)\n",
    "svc_params = [\n",
    "    dict(svm__C=[0.5, 1.0, 5.0], svm__kernel=['poly'], svm__gamma=[0.1, 0.01, 0.5], svm__degree=[1, 2, 3, 4]),\n",
    "    dict(svm__C=[0.5, 1.0, 5.0], svm__kernel=['rbf'], svm__gamma=[0.1, 0.01, 0.5])]\n",
    "gs1 = grid_search.RandomizedSearchCV(clf, svc_params[0], n_jobs=-1, n_iter=36)\n",
    "gs1.fit(X[:2500], y[:2500])\n",
    "x1 = gs1.score(X, y)\n",
    "gs2 = grid_search.RandomizedSearchCV(clf, svc_params[1], n_jobs=-1, n_iter=9)\n",
    "gs2.fit(X[:2500], y[:2500])\n",
    "x2 = gs2.score(X, y)\n",
    "x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(gs1.grid_scores_, key=itemgetter(1), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(gs2.grid_scores_, key=itemgetter(1), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outstanding parameters with good mean and low variance per fold were the ones defined in the following pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56017876633529018"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = pipeline.Pipeline(steps=[\n",
    "        ('scaling', preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True)), \n",
    "        ('svm', svm.SVC(C=5.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "                    decision_function_shape=None, degree=3, gamma=0.5, kernel='poly',\n",
    "                    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "                    tol=0.001, verbose=False))])\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, train_size=0.07)\n",
    "clf.fit(X_train, y_train)\n",
    "merge.precision(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55975226677274659"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfT = tree.DecisionTreeClassifier()\n",
    "tree_params = dict(criterion=['gini', 'entropy'], max_features=[2, 4, 8, 10], \n",
    "                   max_depth=[2, 4, 8, 100], min_samples_split=[2, 4, 8, 30, 100],\n",
    "                   min_samples_leaf=[1, 4, 32, 100])\n",
    "gsT = grid_search.RandomizedSearchCV(clfT, tree_params, n_iter=200)\n",
    "gsT.fit(X[:40000], y[:40000])\n",
    "gsT.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(gsT.grid_scores_, key=itemgetter(1), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimized parameters against overfitting:\n",
    "```\n",
    "'criterion': 'gini', 'max_depth': 4, 'max_features': 8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56013808554902722"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfTg = tree.DecisionTreeClassifier(criterion='gini', max_depth=4, max_features=8, min_samples_leaf=100)\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, train_size=0.7)\n",
    "clfTg.fit(X_train, y_train)\n",
    "merge.precision(clfTg.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the following the logical proof that we are not overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56200875159462838"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfT.fit(X, y)\n",
    "merge.precision(clfTg.predict(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfF = ensemble.RandomForestClassifier(n_jobs=-1)\n",
    "tree_params = dict(criterion=['gini', 'entropy'], max_features=[2, 4, 'auto'], \n",
    "                   max_depth=[2, 4, 8, 100], min_samples_split=[2, 4, 8, 30, 100],\n",
    "                   min_samples_leaf=[1, 4, 32, 100])\n",
    "gsF = grid_search.RandomizedSearchCV(clfF, tree_params, n_iter=175)\n",
    "gsF.fit(X[:40000], y[:40000])\n",
    "gsF.score(X[40000:], y[:40000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(gsF.grid_scores_, key=itemgetter(1), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimized paramters for Random Forest using k-fold:\n",
    "```\n",
    "'min_samples_leaf': 32, 'min_samples_split': 2, 'criterion': 'gini', 'max_depth': 8, 'max_features': 4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56722130011933991"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfF = ensemble.RandomForestClassifier(n_jobs=-1, min_samples_leaf=32, min_samples_split=2, criterion='gini',\n",
    "                                       max_depth=8, max_features=4)\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, train_size=0.5)\n",
    "clfF.fit(X_train, y_train)\n",
    "merge.precision(clfF.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Furthermore no overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5800263370872828"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfF.fit(X, y)\n",
    "merge.precision(clfF.predict(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best performer: Random Forest\n",
    "Random forest should now be trained on test_train, evaluated on test_predictions. After evaluating and another kross-validation on test_train the parameters can be used to predict final binary labels on class_predictions after learning on class_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.56942666666666664, 0.56942666666666664)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfF = ensemble.RandomForestClassifier(n_jobs=-1)\n",
    "tree_params = dict(criterion=['gini'], max_features=[4, 'auto'], \n",
    "                   max_depth=[4, 8, 100], min_samples_split=[2, 8, 30, 100],\n",
    "                   min_samples_leaf=[4, 32])\n",
    "gsF = grid_search.RandomizedSearchCV(clfF, tree_params, n_iter=48, n_jobs=-1)\n",
    "gsF.fit(X[75000:], y[75000:])\n",
    "gsF.score(X[:75000], y[:75000]), merge.precision(gsF.predict(X[:75000]), y[:75000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.56590, std: 0.00064, params: {'max_depth': 8, 'criterion': 'gini', 'min_samples_split': 30, 'min_samples_leaf': 32, 'max_features': 4},\n",
       " mean: 0.56548, std: 0.00205, params: {'max_depth': 8, 'criterion': 'gini', 'min_samples_split': 100, 'min_samples_leaf': 4, 'max_features': 'auto'},\n",
       " mean: 0.56531, std: 0.00163, params: {'max_depth': 8, 'criterion': 'gini', 'min_samples_split': 8, 'min_samples_leaf': 32, 'max_features': 'auto'},\n",
       " mean: 0.56531, std: 0.00163, params: {'max_depth': 8, 'criterion': 'gini', 'min_samples_split': 30, 'min_samples_leaf': 32, 'max_features': 'auto'},\n",
       " mean: 0.56480, std: 0.00117, params: {'max_depth': 8, 'criterion': 'gini', 'min_samples_split': 100, 'min_samples_leaf': 32, 'max_features': 4},\n",
       " mean: 0.56470, std: 0.00372, params: {'max_depth': 4, 'criterion': 'gini', 'min_samples_split': 8, 'min_samples_leaf': 32, 'max_features': 4},\n",
       " mean: 0.56449, std: 0.00157, params: {'max_depth': 8, 'criterion': 'gini', 'min_samples_split': 2, 'min_samples_leaf': 32, 'max_features': 4},\n",
       " mean: 0.56449, std: 0.00157, params: {'max_depth': 8, 'criterion': 'gini', 'min_samples_split': 8, 'min_samples_leaf': 32, 'max_features': 4},\n",
       " mean: 0.56445, std: 0.00355, params: {'max_depth': 4, 'criterion': 'gini', 'min_samples_split': 2, 'min_samples_leaf': 32, 'max_features': 4},\n",
       " mean: 0.56440, std: 0.00184, params: {'max_depth': 4, 'criterion': 'gini', 'min_samples_split': 100, 'min_samples_leaf': 32, 'max_features': 'auto'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(gsF.grid_scores_, key=itemgetter(1), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[mean: 0.56837, std: 0.00299, params: {'min_samples_leaf': 32, 'min_samples_split': 30, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto'},\n",
    " mean: 0.56736, std: 0.00163, params: {'min_samples_leaf': 32, 'min_samples_split': 8, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto'},\n",
    " mean: 0.56722, std: 0.00162, params: {'min_samples_leaf': 32, 'min_samples_split': 2, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto'},\n",
    " mean: 0.56709, std: 0.00244, params: {'min_samples_leaf': 4, 'min_samples_split': 30, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto'},\n",
    " mean: 0.56699, std: 0.00237, params: {'min_samples_leaf': 4, 'min_samples_split': 2, 'criterion': 'gini', 'max_depth': 8, 'max_features': 4},\n",
    " mean: 0.56699, std: 0.00237, params: {'min_samples_leaf': 4, 'min_samples_split': 8, 'criterion': 'gini', 'max_depth': 8, 'max_features': 4},\n",
    " mean: 0.56696, std: 0.00400, params: {'min_samples_leaf': 4, 'min_samples_split': 100, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto'},\n",
    " mean: 0.56688, std: 0.00190, params: {'min_samples_leaf': 32, 'min_samples_split': 100, 'criterion': 'gini', 'max_depth': 8, 'max_features': 4},\n",
    " mean: 0.56671, std: 0.00460, params: {'min_samples_leaf': 4, 'min_samples_split': 100, 'criterion': 'gini', 'max_depth': 8, 'max_features': 4},\n",
    " mean: 0.56665, std: 0.00322, params: {'min_samples_leaf': 32, 'min_samples_split': 100, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto'}]\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following configuration has a low variance high mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clfF = ensemble.RandomForestClassifier(n_jobs=-1, min_samples_leaf=32, min_samples_split=2, criterion='gini',\n",
    "                                       max_depth=8, max_features=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56970792327379227"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfF.fit(X[:70000], y[:70000])\n",
    "merge.precision(clfF.predict(X[70000:]), y[70000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall precision is calculated by the following rule $prec = \\frac{prec_{agree} size_{agree}}{size_test} + \\frac{prec_{disagree} size_{disagree}}{size_test}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66858996896942602"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline * baseline_weight / len(test_predictions) + c * len(y_labels) / len(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming we can be as precise when predicting on the class set we use as our precision for disagreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67156004576754724"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec_merge = merge.precision(clfF.predict(X[70000:]), y[70000:])\n",
    "baseline * baseline_weight / len(test_predictions) + prec_merge * len(y_labels) / len(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And would obtain a result which is around $0.3%$ better.\n",
    "\n",
    "# Merge predictions after training a classifier (estimated precision 0.672)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = ['articleID', 'productGroup', 'customerID', 'voucherID']\n",
    "X_train, y_train = merge.boosting_features(test_train, test_imputed, categories)\n",
    "X_class, class_dis, class_agr = merge.class_features(class_train, class_imputed, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clfF.fit(X_train, y_train)\n",
    "y_merged = clfF.predict(X_class)\n",
    "class_dis['merged_prediction'] = y_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_agr['merged_prediction'] = class_imputed.prediction.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_unified = pd.concat([class_dis, class_agr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class_unified now contains the final prediction by learning to select predictions from classifiers on the test set and running it on the class data. The classifier is prevented from overfitting as shown above and is evaluated using CV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FINAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orderID   articleID  colorCode  sizeCode\n",
       "a1744179  i1001147   1001       42          0\n",
       "          i1001151   3082       42          0\n",
       "          i1001461   2493       42          0\n",
       "          i1001480   1001       42          0\n",
       "          i1003229   2112       42          0\n",
       "a1744181  i1003656   7178       29          0\n",
       "a1744184  i1003520   7126       33          0\n",
       "          i1003863   3001       38          0\n",
       "                     3086       42          1\n",
       "a1744187  i1003276   1111       36          1\n",
       "                     1493       36          1\n",
       "a1744195  i1003920   1092       36          1\n",
       "a1744196  i1003248   1001       44          0\n",
       "          i1003270   1082       44          0\n",
       "a1744199  i1003190   1493       44          1\n",
       "          i1003211   1493       42          1\n",
       "a1744203  i1001165   1001       44          0\n",
       "a1744204  i1001443   1001       38          0\n",
       "a1744210  i1001281   1055       40          0\n",
       "          i1003857   1078       40          1\n",
       "          i1003870   1001       40          1\n",
       "          i1003887   1079       40          1\n",
       "a1744211  i1003679   7215       30          1\n",
       "a1744212  i1000477   1091       36          1\n",
       "          i1003980   1001       34          1\n",
       "a1744214  i1002633   3097       I           0\n",
       "          i1003149   1493       42          1\n",
       "          i1003265   1493       42          1\n",
       "a1744215  i1001114   1088       34          0\n",
       "          i1003606   7169       25          0\n",
       "                                           ..\n",
       "a1855487  i1001147   1001       34          1\n",
       "          i1001163   1109       34          1\n",
       "                                36          1\n",
       "          i1001168   1001       34          1\n",
       "                     1115       34          1\n",
       "          i1002581   1093       I           1\n",
       "          i1002598   1092       I           1\n",
       "                     1096       I           1\n",
       "                     1112       I           1\n",
       "          i1002636   3097       I           1\n",
       "          i1003944   1082       34          1\n",
       "a1855489  i1001138   1096       36          0\n",
       "          i1002506   1012       38          0\n",
       "a1855490  i1003941   1082       44          0\n",
       "a1855491  i1003274   3097       40          1\n",
       "a1855492  i1004338   20197      40          0\n",
       "a1855493  i1001163   1111       38          0\n",
       "a1855494  i1001155   1001       38          0\n",
       "a1855495  i1003660   7211       30          1\n",
       "          i1003956   1113       40          1\n",
       "a1855496  i1004181   10114      40          1\n",
       "          i1004213   10001      40          1\n",
       "          i1004332   10001      40          1\n",
       "          i1004341   10108      40          1\n",
       "a1855497  i1004237   10342      40          0\n",
       "          i1004481   30107      A           0\n",
       "a1855498  i1001563   1090       40          0\n",
       "a1855501  i1001099   3085       42          0\n",
       "          i1004207   10107      42          0\n",
       "a1855502  i1002423   1116       38          0\n",
       "Name: merged_prediction, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_unified.merged_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the same approach for the test set (assurance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = ['articleID', 'productGroup', 'customerID', 'voucherID']\n",
    "X_traint, y_traint = merge.boosting_features(test_train, test_imputed, categories)\n",
    "X_testt, class_dist, class_agrt = merge.class_features(test_train, test_imputed, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clfF.fit(X_traint, y_traint)\n",
    "y_mergedt = clfF.predict(X_testt)\n",
    "class_dist['merged_prediction'] = y_mergedt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_agrt['merged_prediction'] = test_imputed.prediction.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_unifiedt = pd.concat([class_dist, class_agrt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67416730249922319"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_unifiedt['prediction_true'] = test_imputed.original.returnQuantity.astype(int)\n",
    "merge.precision(class_unifiedt.merged_prediction, class_unifiedt.prediction_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows that the approach works. Indeed the forest is overfitting here because of evaluation on training data but the previous rows are just to make sure everything works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}